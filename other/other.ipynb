{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8ed9cc-959a-4111-b17c-8dc69bc5dc0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45caa662-776a-4d4e-bfb9-0f65c7ebfb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "categoryFeatures = ['!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!']\n",
    "params = {\n",
    "    'boosting_type': 'GBDT',\n",
    "    'objective':\"binary\",\n",
    "    'metric':'binary_logloss',\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "for i in range(20):\n",
    "\tpositive_count_train = y.value_counts()[1]\n",
    "\tsampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, 1: positive_count_train},random_state=i, replacement=True)\n",
    "\tX_re, y_re = sampler.fit_resample(X, y)\n",
    "\t\n",
    "\tlgb_train = lgb.Dataset(X_re.drop(\"Id\",axis=1), y_re,free_raw_data=False)\n",
    "\tmodel = lgb.train(params, lgb_train, \n",
    "\t\t\t\t\t  categorical_feature = categoryFeatures,\n",
    "\t\t\t\t\t  num_boost_round=500)\n",
    "\tpred = model.predict(X_test.drop(\"Id\",axis=1),num_iteration=model.best_iteration)\n",
    "\tif i == 0:\n",
    "\t\toutput2 = pd.DataFrame(pred, columns=['pred' + str(i + 1)])\n",
    "\telse:\n",
    "\t\toutput = pd.DataFrame(pred, columns=['pred' + str(i + 1)])\n",
    "\t\toutput2 = pd.concat([output2, output], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458db7d6-77cc-4375-93e3-110fe9a98da4",
   "metadata": {},
   "source": [
    "Вариант балансировка классов когда мы берем нулевой класс рандомно, и по количеству сопоставимо с первым классом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5183aaa-a858-40c9-99ff-1e0a9cff5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(df_lc.select_dtypes(include=['object']).columns)\n",
    "numeric_features = list(set(df_lc.columns) - (set(categorical_features) | set(['target'])))\n",
    "all_features = categorical_features + numeric_features\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы данных\n",
    "train, test = train_test_split(df_lc, test_size=0.2, random_state=42)\n",
    "\n",
    "# Отбор данных класса 1\n",
    "class_1 = train[train['target'] == 1]\n",
    "# Отбор данных класса 0\n",
    "class_0 = train[train['target'] == 0].sample(n=len(class_1)*2, random_state=42)\n",
    "# Объединение выборок\n",
    "balanced_train = pd.concat([class_1, class_0])\n",
    "\n",
    "X_train_b = balanced_train[all_features]\n",
    "y_train_b = balanced_train['target']\n",
    "\n",
    "X_test_b = test[all_features]\n",
    "y_test_b = test['target']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78895a2a-837b-4f58-8866-2e39e425f2d3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec3e417-1046-4b5e-a89b-c09883a731ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def plot_histogram(data, column, bins=30, kde=True, color='blue'):\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.histplot(data[column], bins=bins, kde=kde, color=color, log_scale = True)\n",
    "    plt.title(f'Histogram and KDE of {column}') #Kernel Density Estimation (ядерное сглаживание)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.xlim([1e-6,1])\n",
    "    plt.ylim([0,4e5])\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplot(data, column):\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(y=data[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    plt.ylabel(column)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_scatter(data, x_col, y_col):\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=data, x=x_col, y=y_col)\n",
    "    plt.title(f'Scatter Plot between {x_col} and {y_col}')\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_qq(data, column):\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    stats.probplot(data[column], dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q plot of {column}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289b932-2e9b-4d32-bae5-c6eb38c13cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "# Создаем тепловую карту\n",
    "plt.figure(figsize=(10, 8))  \n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5, cbar=True)\n",
    "plt.title('Тепловая карта корреляций')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883aa0a-b82d-48de-b163-dcc899bcd012",
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_info.drop(\"sex\", axis=1).hist(figsize=(20, 15), layout=(-1, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8140a9-b672-4bab-be04-17ee8b2cb0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme()  # Тут можно задать стили\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=rides_info,\n",
    "    x=\"ride_date\",\n",
    "    y=\"deviation_normal\",\n",
    "    hue=\"target_class\",\n",
    "    kind=\"line\",  # или scatter\n",
    "    aspect=4,\n",
    ")\n",
    "g.set_xticklabels(rotation=45, horizontalalignment=\"right\", step=2);\n",
    "\n",
    "- Замечаем точки перегиба\n",
    "- Замечаем точки входа\n",
    "- Возможно углы наклона до перегиба"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c38ff6-c8d0-4382-b9bb-278d6f217f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Когорты\n",
    "Cog = df.pivot_table(index = 'столбец месяц первой покупки',columns = 'столбец индекс',values = 'суммируемая величина (ID)', aggfunc = len)\n",
    "aggfunc  len - кол-во sum -сумма pd.Series.nunique - кол-во уникальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22262e72-62c2-4e22-92b6-8ca7a6e9c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/a-milenkin/Competitive_Data_Science/blob/main/notebooks/2.3%20-%20Visualisation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58569e73-853d-47ab-bf34-eec3ce9e6327",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0c217-4fce-4a62-8852-c033b6bf14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple\n",
    "numerical = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "for feat in numerical:\n",
    "    df[feat].fillna(df[feat].median(), inplace=True)\n",
    "df.isnull().sum() # проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76648f-b865-4153-a357-91f65b68185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn\n",
    "# ищет ближайших соседей и усредняет значения колонки по ближайшим соседям \n",
    "from sklearn.impute import KNNImputer\n",
    "def fill_empty(df):\n",
    "    featuresWithNulls = df.columns[df.isnull().any()]\n",
    "    imputer = KNNImputer(n_neighbors=5) \n",
    "    df[featuresWithNulls] = imputer.fit_transform(df[featuresWithNulls])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c946c-ef1c-435a-b9b9-2ab2989f8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn\n",
    "# ищет ближайших соседей и усредняет значения колонки по ближайшим соседям \n",
    "from sklearn.impute import KNNImputer\n",
    "def fill_empty(df):\n",
    "    # Стандартизация признаков\n",
    "    scaler = StandardScaler()\n",
    "    scaled_df = scaler.fit_transform(df)\n",
    "    scaled_df = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "    \n",
    "    # Определение признаков по которым происходит поиск соседей\n",
    "    featuresWithNulls = scaled_df.columns[scaled_df.isnull().any()]\n",
    "    # Применение KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    scaled_df[featuresWithNulls] = imputer.fit_transform(scaled_df[featuresWithNulls])\n",
    "    \n",
    "    # Возвращение данных к исходному масштабу\n",
    "    return pd.DataFrame(scaler.inverse_transform(scaled_df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de1f38-e529-40f4-9fc4-6328d2888fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knn\n",
    "# ищет ближайших соседей и усредняет значения колонки по ближайшим соседям \n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "columns_for_imputation = ['feature1', 'feature2']\n",
    "nn = NearestNeighbors(n_neighbors=5)\n",
    "nn.fit(df[columns_for_imputation])\n",
    "\n",
    "# Для примера выводим расстояния для первой строки\n",
    "distances, indices = nn.kneighbors([df.iloc[0][columns_for_imputation].to_numpy()])\n",
    "print(\"Расстояния:\", distances)\n",
    "print(\"Индексы ближайших соседей:\", indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e20203-d4b5-49c8-9f61-c353dc0b699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include=['object']).columns\n",
    "for feat in categorical:\n",
    "    df[feat].fillna(df[feat].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71e44f-7500-4a8d-bcd8-23dda8e3ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Интерполяция\n",
    "Метод .interpolate() Имеет возможности линейной, полиномиальной, экспоненциальной, временной и пр. интерполяции."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314313b4-0e01-4fa7-91ed-91633ae309cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Оценка выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aca223-0c73-4f05-9d13-40cc342f5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers_3sigma(df, col):\n",
    "    mat=df[col].mean()\n",
    "    sigma = (((df[col] - mat)**2).sum()/len(df[col]))**(1/2)\n",
    "    interval = (mat-3*sigma,mat+3*sigma)\n",
    "    \n",
    "    #формируем границы интервала (по сути это фильтр)\n",
    "    is_outlier = (df[col] < interval[0]) | (df[col] > interval[1])\n",
    "   \n",
    "    #процент вышедших за пределы интервала\n",
    "    outlier = pd.DataFrame()\n",
    "    outlier['col'] = np.array([col])\n",
    "    proc = round(is_outlier.sum()/len(df)*100,0)\n",
    "    outlier['%'] = np.array([proc])\n",
    "    outlier['-3Sig'] = np.array([round(interval[0],2)])\n",
    "    outlier['+3Sig'] = np.array([round(interval[1],2)])\n",
    "           \n",
    "    lst_out= list(is_outlier[is_outlier==True].index)\n",
    "    outlier['ind'] = 1\n",
    "    outlier['ind'] = outlier['ind'].astype('object')\n",
    "    outlier.at[0,'ind'] = lst_out\n",
    "    #возвращает фильтр на строки где есть выбросы\n",
    "    return outlier, is_outlier \n",
    "\n",
    "# USES\n",
    "\n",
    "colum = df_faiss.select_dtypes('number').columns\n",
    "out_of_data = pd.DataFrame()\n",
    "for j in colum:\n",
    "    outlier, is_outlier = calculate_outliers_3sigma(df,j) # изменить DF\n",
    "    out_of_data = pd.concat([out_of_data,outlier])\n",
    "out_of_data.set_index('col', inplace=True) \n",
    "\n",
    "# Проверка выбросов\n",
    "check_indx = out_of_data.loc[признак,'ind']\n",
    "df[df.index.isin(check_indx)].признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1b8c0-4efb-4adf-8c1a-65cd7ce22c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers_percentile(df, col, lower_percentile=1, upper_percentile=99):\n",
    "       # Вычисление перцентильных значений\n",
    "    lower_bound = np.percentile(df[col].dropna(), lower_percentile)\n",
    "    upper_bound = np.percentile(df[col].dropna(), upper_percentile)\n",
    "    \n",
    "    # Формирование фильтра выбросов\n",
    "    is_outlier = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "    \n",
    "    # Подсчёт процента выбросов\n",
    "    outlier = pd.DataFrame()\n",
    "    outlier['col'] = np.array([col])\n",
    "    percent_outliers = round(is_outlier.mean() * 100, 2)\n",
    "    outlier['%'] = np.array([percent_outliers])\n",
    "    outlier['LowerBound'] = np.array([round(lower_bound, 2)])\n",
    "    outlier['UpperBound'] = np.array([round(upper_bound, 2)])\n",
    "    \n",
    "    # Сохранение индексов выбросов\n",
    "    list_outliers = list(is_outlier[is_outlier].index)\n",
    "    outlier['ind'] = 1\n",
    "    outlier['ind'] = outlier['ind'].astype('object')\n",
    "    outlier.at[0, 'ind'] = list_outliers\n",
    "    \n",
    "    # Возвращает статистику по выбросам и фильтр\n",
    "    return outlier, is_outlier\n",
    "\n",
    "# USES\n",
    "colum = df_faiss.select_dtypes('number').columns\n",
    "out_of_data = pd.DataFrame()\n",
    "for j in colum:\n",
    "    outlier, is_outlier = calculate_outliers_percentile(df, j) # изменить DF\n",
    "    out_of_data = pd.concat([out_of_data,outlier])\n",
    "out_of_data.set_index('col', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada72a45-484d-4480-9a96-127502f309c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Энкодеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07032140-acf4-4fea-a6c3-67c608e95cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for column in ['Fruit', 'Color']:\n",
    "    df[column + '_encoded'] = encoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c019d-82ee-46af-b697-e316e557b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from category_encoders import BinaryEncoder\n",
    "\n",
    "encoder = BinaryEncoder(cols=['Fruit'], drop_invariant=True)  # 'cols' указывает \n",
    "df_encoded = encoder.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2878a-916a-4f31-8747-605f99a41b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = df[признак].value_counts() / df.shape[0]\n",
    "df[признак_новый] = df[признак].map(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5493f-d70c-43ec-ab0b-6ec0b8f78ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode(df, categorical_col, target_col, smoothing=1):\n",
    "    # Вычисляем глобальное среднее значение целевой переменной\n",
    "    mean = df[target_col].mean()\n",
    "    # Агрегация среднего по категориям\n",
    "    agg = df.groupby(categorical_col)[target_col].agg(['count', 'mean'])\n",
    "    # Вычисляем сглаженные средние\n",
    "    counts = agg['count']\n",
    "    means = agg['mean']\n",
    "    smooth = (counts * means + smoothing * mean) / (counts + smoothing)\n",
    "    \n",
    "    return df[categorical_col].map(smooth)\n",
    "\n",
    "\n",
    "data['category_encoded'] = target_encode(data, 'category', 'target', smoothing=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d09e3-b3c8-463a-a446-619fb614d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бинарное дерево\n",
    "class Node:\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "\n",
    "    def insert(self, node):\n",
    "\n",
    "        if self.key > node.key:\n",
    "            if self.left is None:\n",
    "                self.left = node\n",
    "            else:\n",
    "                self.left.insert(node)\n",
    "\n",
    "        elif self.key < node.key:\n",
    "            if self.right is None:\n",
    "                self.right = node\n",
    "            else:\n",
    "                self.right.insert(node)\n",
    "\n",
    "# Использование класса Node и метода insert\n",
    "root = Node(10)\n",
    "root.insert(Node(5))\n",
    "root.insert(Node(15))\n",
    "root.insert(Node(3)) \n",
    "root.insert(Node(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91afa7ff-b31a-4bcf-a3d8-baf76937c4f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de56ae5-b0a7-45a8-8d2c-869b8200e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "categorical_features = list(df.select_dtypes(include=['object']).columns)\n",
    "numeric_features = list(set(df.columns) - (set(categorical_features) | set(['is_promoted','employee_id'])))\n",
    "\n",
    "X = df[categorical_features + numeric_features]\n",
    "y = df['is_promoted']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    learning_rate=0.1,\n",
    "    depth=3,\n",
    "    cat_features=categorical_features,\n",
    "    verbose=10,\n",
    "    #auto_class_weights='Balanced'\n",
    ")\n",
    "model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "# Предсказание и оценка \n",
    "threshold =0.7\n",
    "y_proba = model.predict_proba(X_test)[:, 1]  \n",
    "y_pred = (y_proba>=threshold).astype(int)\n",
    "\n",
    "\n",
    "# вероятности для класса 1 # Расчет метрик \n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Вычисление Precision, Recall и F1 Score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(include_values=True, cmap='coolwarm', ax=None, xticks_rotation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4dabb9-4d54-4d96-be24-00d3419b3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Получение и сохранение результатов на валидационном наборе\n",
    "    predictions = model_mango_lc1.predict_proba(X_valid_fold)[:, 1]\n",
    "    fold_result = {\n",
    "        'fold_number': fold_number,\n",
    "        'validation_AUC': model_mango_lc1.best_score_['validation']['AUC'],\n",
    "        'best_iteration': model_mango_lc1.get_best_iteration()}\n",
    "                      \n",
    "    fold_results.append(fold_result)\n",
    "\n",
    "\n",
    "    print(f\"Результаты для фолда {fold_number}:\")\n",
    "    print(f\"Лучшая итерация: {model_mango_lc1.get_best_iteration()}\")\n",
    "    print(f\"Точность на валидации: {model_mango_lc1.best_score_['validation']['AUC']:.2f}\")\n",
    "\n",
    "print('Итоги кросс-валидации:')\n",
    "for result in fold_results:\n",
    "    print(f\"Фолд {result['fold_number']}: Лучшая итерация - {result['best_iteration']}, Accuracy - {result['validation_AUC']:.2f}\")\n",
    "```\n",
    "Eval_metric может быть даже кастомный. Для использования нужно ее указать как eval_metric = custom_metric_object\n",
    "```Python\n",
    "from catboost import metrics\n",
    "\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Ваши вычисления здесь, как в вашем примере выше\n",
    "    N0, N1 = np.bincount(y_true)\n",
    "    \n",
    "    y0 = np.where(y_true == 0, 1, 0)\n",
    "    y1 = np.where(y_true == 1, 1, 0)\n",
    "    \n",
    "    eps = 1e-15\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    p0 = np.log(1 - y_pred)\n",
    "    p1 = np.log(y_pred)\n",
    "    return -(1 / N0 * np.sum(y0 * p0) + 1 / N1 * np.sum(y1 * p1)) * 0.5\n",
    "\n",
    "# Создание объекта метрики для CatBoost\n",
    "custom_metric_object = metrics.make_single_metric('balanced_log_loss', balanced_log_loss, is_max_optimal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f652d920-c23b-4eff-84ae-dafd8a6c514f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Рекурсивный отбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b50819-0923-431e-8e00-bfd162b07cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_by_roc_auc(df, features, target = 'target'):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    removed_features = []\n",
    "    roc_aucs = []\n",
    "    current_roc_auc = 0.9\n",
    "\n",
    "\n",
    "    for feature in features:\n",
    "        # Тренируем модель без одного признака\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X.drop(feature, axis=1), y, test_size=0.2, random_state=42)\n",
    "        categorical_features = list(X.drop(feature, axis=1).select_dtypes(include=['object']).columns)\n",
    "        encoder = TargetEncoder(cols = categorical_features)\n",
    "        X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "        X_test_encoded = encoder.transform(X_test)\n",
    "        \n",
    "        model = LGBMClassifier(is_unbalance = True, random_state=42)\n",
    "        model.fit(X_train_encoded, y_train)\n",
    "        \n",
    "        y_pred_prob = model.predict_proba(X_test_encoded)[:, 1]\n",
    "        new_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        print(f\"{feature} : {new_roc_auc}\")\n",
    "        roc_aucs.append(new_roc_auc)\n",
    "\n",
    "\n",
    "        # Проверяем, улучшился ли ROC AUC достаточно, чтобы исключить признак\n",
    "        if new_roc_auc > current_roc_auc + 0.005:\n",
    "            removed_features.append(feature)\n",
    "            current_roc_auc = new_roc_auc\n",
    "            X.drop(feature, axis=1, inplace=True)  # Удаляем признак навсегда\n",
    "        else:\n",
    "            # Если не улучшилось достаточно, возвращаем признак обратно\n",
    "            continue\n",
    "\n",
    "\n",
    "    return removed_features, roc_aucs\n",
    "\n",
    "\n",
    "\n",
    "removed_features, roc_aucs = feature_selection_by_roc_auc(df, all_features)\n",
    "print(\"Removed features:\", removed_features)\n",
    "print(\"ROC AUCs for each step:\", roc_aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c647cd-7f4c-40c5-add1-fa256127f1aa",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c6ac7-5190-4b0a-bdd1-99ec6d10b97c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e95004-60f2-46a6-86e1-82cb17ce1989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "X = df_lc[all_features]\n",
    "y = df_lc['target']\n",
    "\n",
    "categorical_features = list(df_lc.select_dtypes(include=['object']).columns)\n",
    "numeric_features = list(set(df_lc.columns) - (set(categorical_features) | set(['target'])))\n",
    "all_features = categorical_features + numeric_features\n",
    "\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_tmp, y_tmp, test_size=0.2, random_state=42, stratify = y_tmp)\n",
    "\n",
    "encoder = TargetEncoder(cols = categorical_features) # ЭНКОДЕ НА ТРЕНИРОВКЕ И НА ОБУЧЕНИИ ЭТО ОДИН ЭНКОДЕР\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "X_valid_encoded = encoder.transform(X_valid)\n",
    "\n",
    "lgb_params = {\n",
    "    'is_unbalance': True,\n",
    "    #'learning_rate': 0.1,\n",
    "    #'max_depth': 50,\n",
    "    #'n_estimators': 1000,\n",
    "    #'num_leaves': 31,\n",
    "    #'min_child_samples': 20,\n",
    "    #'min_split_gain': 0,\n",
    "    #'subsample': 0.8,\n",
    "    #'subsample_freq': 5,\n",
    "    #'colsample_bytree': 0.8,\n",
    "    #'reg_alpha': 0,\n",
    "    #'objective': 'binary',\n",
    "    #'reg_lambda': 1,\n",
    "    #'scale_pos_weight': 1,\n",
    "    #'n_jobs': 15,\n",
    "    'verbose': 10\n",
    "\n",
    "model = lgb.LGBMClassifier(**lgb_params)\n",
    "model.fit(\n",
    "    X_train_encoded, \n",
    "    y_train, \n",
    "    eval_set = [(X_valid_encoded, y_valid)], \n",
    "    eval_metric = 'binary_loss', \n",
    "    early_stopping_rounds = 30, \n",
    "    verbose = True)\n",
    "}\n",
    "\n",
    "# Предсказание и оценка \n",
    "threshold =0.9\n",
    "y_proba = model.predict_proba(X_test_encoded)[:, 1]  \n",
    "y_pred = (y_proba>=threshold).astype(int)\n",
    "\n",
    "\n",
    "# вероятности для класса 1 # Расчет метрик \n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Вычисление Precision, Recall и F1 Score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b927b05-5cb0-4fec-8337-93363cf2fd64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LGBM + hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c0ecc-12d4-4226-bb9c-1e000423641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пространство поиска\n",
    "param_space = {\n",
    "    'learning_rate': hp.choice('learning_rate', [0.1]),  # только одно значение для упрощения\n",
    "    'n_estimators' : hp.choice('n_estimators', [500]),\n",
    "    'min_child_samples' : scope.int(hp.quniform('min_child_samples', 10, 200, 1)),\n",
    "    'min_split_gain' : hp.uniform('min_split_gain', 0, 1),\n",
    "    'subsample' : hp.uniform('subsample', 0.1, 1),\n",
    "    'subsample_freq' : scope.int(hp.quniform('subsample_freq', 1, 10, 1)),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1, 0.1),\n",
    "    'reg_alpha' : scope.int(hp.quniform('reg_alpha', 1, 10, 1)),\n",
    "    'reg_lambda' : scope.int(hp.quniform('reg_lambda', 1, 10, 1)),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)), \n",
    "    'scale_pos_weight': scope.int(hp.quniform('scale_pos_weight', 1, 30, 1)),\n",
    "    'num_leaves': scope.int(hp.quniform('num_leaves', 2, 200, 1))       \n",
    "}\n",
    "\n",
    "\n",
    "# Функция оптимизации с данными\n",
    "optimization_function = partial(optimize, X_train= X_train_encoded, X_valid = X_valid_encoded, y_train= y_train, y_valid= y_valid)\n",
    "\n",
    "\n",
    "# Запуск оптимизации\n",
    "trials = Trials()\n",
    "best_params = fmin(optimization_function, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "\n",
    "print(\"Лучшие параметры:\")\n",
    "print(space_eval(param_space, best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5f3f0-9466-497b-8a5a-01b544d998eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LGBM + Strarified + Kfold + hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8250b5-1c39-4e88-b679-fca510731931",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Создаем объект StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    auc_scores = []\n",
    "\n",
    "\n",
    "    # Создаем таргет энкодер для категориальных переменных\n",
    "    if categorical_features:\n",
    "        encoder = TargetEncoder(cols=categorical_features)\n",
    "\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Применяем таргет энкодер, если есть категориальные переменные\n",
    "        if categorical_features:\n",
    "            X_train[categorical_features] = encoder.fit_transform(X_train[categorical_features], y_train)\n",
    "            X_test[categorical_features] = encoder.transform(X_test[categorical_features])\n",
    "        \n",
    "        # Обучаем модель на текущем фолде\n",
    "        model = lgb.LGBMClassifier(**params, n_jobs=-1)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=10, verbose=False)\n",
    "        \n",
    "        # Оцениваем модель на тестовом фолде\n",
    "        preds = model.predict_proba(X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(y_test, preds)\n",
    "        auc_scores.append(auc_score)\n",
    "    \n",
    "    # Возвращаем средний AUC по всем фолдам\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    return {'loss': -mean_auc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "# Пространство поиска\n",
    "param_space = {\n",
    "    'learning_rate': hp.choice('learning_rate', [0.1]),  # только одно значение для упрощения\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 5, 50, 1)),           \n",
    "    'num_leaves': scope.int(hp.quniform('num_leaves', 2, 200, 1))       \n",
    "}\n",
    "\n",
    "# Функция оптимизации с данными\n",
    "optimization_function = partial(optimize, X=X, y=y, n_folds=3, categorical_features=categorical_features)\n",
    "\n",
    "\n",
    "# Запуск оптимизации\n",
    "trials = Trials()\n",
    "best_params = fmin(optimization_function, space=param_space, algo=tpe.suggest, max_evals=50, trials=trials)\n",
    "\n",
    "\n",
    "print(\"Лучшие параметры:\")\n",
    "print(space_eval(param_space, best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245dc157-42ed-4be4-87bc-0218dd3d0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = space_eval(param_space, best_params)\n",
    "\n",
    "tuned_model = lgb.LGBMClassifier(**new_params)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "tuned_model.fit(X_train_encoded,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8156cc4-b5b7-4bc0-8453-f7a6af3e4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# диапазон параметров для перебора\n",
    "param_space = {\n",
    "     'metric' : hp.choice('metric', ['logloss']),\n",
    "    'learning_rate' : hp.choice('learning_rate', [0.01]),\n",
    "    'max_depth' : scope.int(hp.quniform('max_depth', 5, 50, 1)),\n",
    "    'n_estimators' : hp.choice('n_estimators', [500]),\n",
    "    'num_leaves' : scope.int(hp.quniform('num_leaves', 2, 200, 1)),\n",
    "    'min_child_samples' : scope.int(hp.quniform('min_child_samples', 10, 200, 1)),\n",
    "    'min_split_gain' : hp.uniform('min_split_gain', 0, 1),\n",
    "    'subsample' : hp.uniform('subsample', 0.1, 1),\n",
    "    'subsample_freq' : scope.int(hp.quniform('subsample_freq', 1, 10, 1)),\n",
    "    'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1, 0.1),\n",
    "    'reg_alpha' : scope.int(hp.quniform('reg_alpha', 1, 10, 1)),\n",
    "    'reg_lambda' : scope.int(hp.quniform('reg_lambda', 1, 10, 1)),\n",
    "    'scale_pos_weight': scope.int(hp.quniform('scale_pos_weight', 1, 30, 1)),\n",
    "    'random_state' : hp.choice('random_state', [22]),\n",
    "    'objective' : hp.choice('objective', ['binary']),\n",
    "    'verbose' : hp.choice('verbose', [-1])\n",
    "}\n",
    "\n",
    "# Получение важности признаков\n",
    "feature_imp = pd.DataFrame({'cols':X_train.columns,'importances':estimator_base.feature_importances_}).sort_values(by ='importances',ascending = False).head(15)\n",
    "feature_imp\n",
    "\n",
    "model.get_params()\n",
    "model.feature_importances_\n",
    "model.best_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f698795-5483-402e-acf4-f67aa4c59c98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee01f87-409c-4deb-9f66-b20bb0176e24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Group By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d470d-ff4d-45d1-b6b6-8d63c24de3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    ".agg(name = ('column_name','sum'))\n",
    "\n",
    "['column_name'].mean()\n",
    "\t.shift(1) #сдвиг на 1\n",
    "\t.cumsum() #накопленная сумма\n",
    "\t.sample(frac=1/3, random_state=2) # набрать рандомно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d4950-1867-4501-8b77-68be115efacd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Roling (окно скользящего среднего)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c20bcd-0caf-4321-a711-1c2929f127f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('client_id')['sum']\n",
    ".rolling(window =3,min_period = 1) # окно 3, минимально хоть 1 не Nan \n",
    ".mean().reset_index(drop=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951e3fd-dbd3-4ba8-893e-5b0a334b0952",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## соединения таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4507071-2109-4b2b-a3e4-4f1b8cdac573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строк одинаково, не преремешано\n",
    "df_combined = pd.concat([df_1, df_2, df_3], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77108763-fcb2-4a91-8543-994953b4ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Есть колонка индекса и они перемешаны\n",
    "df_1.set_index('index_col', inplace=True)\n",
    "df_2.set_index('index_col', inplace=True)\n",
    "df_3.set_index('index_col', inplace=True)\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df_1, df_2, df_3], axis=1)\n",
    "df_combined.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d9aac0-aacf-4105-b98b-455d604cc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left =data1 , right = data2, on='id', how ='inner') # по id\n",
    "pd.merge(df1, df2, left_index=True, right_index=True) # по индексу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286a919-c0d3-4e39-b1d2-7534826bc784",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## со строками "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b363d3-6928-4549-8b7f-616b8ab0fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.признак.str.lower() / .str.upper()\n",
    "df.признак.str.upper()\n",
    "df.признак.str.len()\n",
    "df.признак.str.strip() # убрать пробелы в начале и в конце\n",
    "df.признак.str[3] # обратиться внутри Series к 3-ему элементу\n",
    "df.признак.str.cat(sep='_') # собрать всю колонку признаков в одну строчку\n",
    "df.признак.str.startswith('G') # True False начинается с ‘G’\n",
    "df.признак.str.endswith('1') # True False заканчивается на ‘G’\n",
    "df.признак.str.replace('Geeks', 'Gulshan') # **замена элемента\n",
    "df.признак.str.count('n') # подсчет кол-ва вхождения эл-ов\n",
    "df.признак.str.find('n') # возвращает индекс найденного\n",
    "df.признак.str.findall('n') # возвращает список вхождения\n",
    "df.признак.str.replace('price','old_price') # переименование колонки\n",
    "df.признак.str.contains('чай') # содержит символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143ad43-35a2-49ba-833c-27edbbf6e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Даты\n",
    "\n",
    "from datetime import date\n",
    "df[признак] = pd.to_datetime(df.признак) # object →  datetime64\n",
    "df[признак]= pd.to_datetime(df.признак,unit ='s') # 5345648 → datetime64\n",
    "df.признак.dt.year # отдельно год (на весь SERIES)\n",
    "# quarter month week day hour minute dayofweek dayofyear\n",
    "df.признак = df.date.dt.strftime('%Y-%m-%d, %H:%M:%S') # форматирование\n",
    "# day (%a Sun) (%A Sunday) (%d 07)\n",
    "# week (%W 01)\n",
    "# month (%b Jan) (%B January) (%m 01)\n",
    "# year (%Y J2022) (%y 22)\n",
    "df[признак] = pd.to_datetime(df[['year', 'month', 'day']]) # сбор даты\n",
    "pd.to_datetime(ratings.timestamp, unit='s') # из вот такого формата '1260759144'\n",
    "date.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05c2fd-deb6-4dd7-9776-009e8afbc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисляет разницу сегодня между дата, чтобы округлить в годах, по строкам где есть NAN\n",
    "((pd.to_datetime('today') - df[признак_дата]) / np.timedelta64(1, 'Y')).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27012c-d75a-449d-abac-344e526eeb63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Чтение и сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77a5ea-2099-46fd-952f-a37b339f3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись\n",
    "df.to_csv('./название.csv',sep = '\\t',index=False)\n",
    "df.to_excel('./название.xlsx',sheet_name='<лист>' , index_label='id' )\n",
    "df.to_json('/content/drive/My Drive/название.json', orient='records', force_ascii=False)\n",
    "df.to_pickle (\"./content/название.pkl\")\n",
    "\n",
    "# Чтение\n",
    "pd.read_csv( './название.csv', sep= ';', index_col= <столбец>)\n",
    "pd.read_excel( './название.xlsx', sheet_name= '<лист>', index_col= <столбец>,dtype ={0:str,1:str})\n",
    "pd.read_json( './название.xlsx', inplace=True)\n",
    "pd.read_pickle ('./название.pkl')\n",
    "\n",
    "# Разное\n",
    "# из CSV в Numpy\n",
    "preds_pers = np.genfromtxt('./название.csv', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301aa3ce-ad3f-4286-8a58-9039d67fd455",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Замена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf389bc-b328-4338-bdc1-96da911dc1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple filter\n",
    "df.loc[:,'y'] = 0.1\n",
    "df.loc[df[\"y\"] > 2, \"y\"] = -1\n",
    "df.loc[df.y.isna(),'y'] = 0.1\n",
    "\n",
    "# WHERE\n",
    "df['new_price'] = np.where(df['price']>100,'expensive','cheap')\n",
    "\n",
    "# MAP\n",
    "mapping_dict = {'red':1, 'blue':2, 'yellow':3}\n",
    "df['n_color'] = df['color'].map(mapping_dict)\n",
    "\n",
    "# APPLY\n",
    "df['new_price'] = df.apply(lambda x: x['price']*1.05 if x['price']>100 and x['name']!='икра' else x['price'], axis =1)\n",
    "\n",
    "#CONDITIONS\n",
    "conditions = [ \n",
    "(df['Age'] < 20), \n",
    "(df['Age'] >= 20) & (df['Age'] < 30), \n",
    "(df['Age'] >= 30) & (df['Age'] < 40), \n",
    "(df['Age'] >= 40) & (df['Age'] < 50), \n",
    "(df['Age'] >= 50) ] \n",
    "\n",
    "choices = [ 'Teenager', 'Twenties', 'Thirties', 'Forties', 'Fifty and older' ]\n",
    "df['Category'] = np.select(conditions, choices, default='Not Specified')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38becb53-1f08-4fbd-ad66-9b924df89240",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Индексы и переименование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd67d81-9891-4d6f-9c93-18de119061fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['id', 'item']) # сделать новые индексы из колонок**\n",
    "df.rename(columns={\"old_name\" : \"new_name\", \"old_name\" : \"new_name\"}, inplace=True)\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8a70b-dc5a-45d3-80f0-31b4edd8f29b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Дубли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f01d896-3be2-43bd-8960-4eebc1e17eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum() # количество дублей\n",
    "df[df.duplicated()==True] # найти дубли\n",
    "df[df.duplicated(keep=False)] # показать оба дубля\n",
    "df = df.drop_duplicates() # удалить дубли\n",
    "df.drop_duplicates(subset=['object_id', 'object', 'type', 'lat', 'lon'], keep=False, inplace=True) #Убрать дубли по набору признаков (убрать оба дубля)\n",
    "df_emb = df_emb.drop_duplicates(subset = 'Code', keep ='first')\n",
    "\n",
    "\n",
    "#сравнить два датафрейма\n",
    "merged = pd.merge(df1,df2, on = list_y, how = 'outer', indicator= True) #list_y - список признаков для сравнения\n",
    "only_in_df1 = merged[merged['_merge']=='left_only']\n",
    "only_in_df2 = merged[merged['_merge']=='right_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbff0be-537a-4dc8-8b1e-3e1dd33ac303",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Типы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c862ee-c8f3-4557-a2ee-90353ef69090",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_dtypes(include=['float64','object']).columns\n",
    "df.название_колонки.describe().apply(lambda x: f\"{x:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5db6c-8b29-4128-9ba9-0f0a30bcb0a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14da30d-8707-4275-93bf-cbd5b2815646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index = 'first_date_cog', columns = 'cogort', values = 'price', aggfunc = sum)\n",
    "# aggfunc: len sum pd.Series.nunique\n",
    "\n",
    "df.pivot_table(index = 'userId',columns = 'movieId', values = 'rating')\n",
    "\n",
    "pd.crosstab(df['userId'], df['movieId'], values=df['rating'], aggfunc='first')\n",
    "\n",
    "# Проверка Nan\n",
    "pivot_df.isnull().all().sum()\n",
    "pivot_df.columns[pivot_df.isnull().all()]\n",
    "pivot_df.index[pivot_df.isnull().all(axis=1)]\n",
    "\n",
    "# Удаление Nan\n",
    "pivot_df = pivot_df.dropna(axis=1, how='all')\n",
    "pivot_df = pivot_df.dropna(axis=0, how='all')\n",
    "pivot_df.loc[1,:]\n",
    "\n",
    "#МУЛЬТИИНДЕКС\n",
    "user_ids = df.index.get_level_values('userId')  \n",
    "movie_ids = df.index.get_level_values('movieId')  \n",
    "specific_user = df.loc[(15.0, 2)]  \n",
    "  \n",
    "for (user_id, movie_id), data in df.iterrows():  \n",
    "    print(f\"User ID: {user_id}, Movie ID: {movie_id}\")  \n",
    "  \n",
    "for userId, df in X_test.groupby('userId'):  \n",
    "    a=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4abea4-92e9-4f87-b21c-67f50a9e086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_col]=df.groupby('user_id',as_index = False)['date'].transform('min')\n",
    "\n",
    "функции трансформ:'min' 'max' 'sum' 'mean'  'nunique'\n",
    ".transform( lambda x: sum([1 if i == 'cancel_order'  else 0 for i in x] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633ff0d-3f5c-4ecd-b488-7211aebd6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Связка `groupby` + `agg()` +  выдуманная функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2825454-faee-443c-9515-f9d38036d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# число уникальных значений\n",
    "f_nuniq = lambda x: x.nunique()\n",
    "\n",
    "# число значений, которые больше чем n\n",
    "more_than_n_func = lambda x, n=8: sum(x > n)\n",
    "\n",
    "# 30% перцентиль / квантиль уровня 0.3\n",
    "def quant_func(x):\n",
    "    return x.quantile(0.3)\n",
    "\n",
    "# Функции поиска первой и второй моды для категориальных значений\n",
    "first_mode = lambda x: x.value_counts().index[0]\n",
    "second_mode = lambda x: x.value_counts().index[1]\n",
    "\n",
    "fix_info_gr = fix_info.groupby(\"car_id\", as_index=False).agg(\n",
    "    \n",
    "    # Все встроенные статистики\n",
    "    worker_count=(\"worker_id\", \"count\"),\n",
    "    work_duration_mean=(\"work_duration\", \"mean\"),\n",
    "    work_duration_max=(\"work_duration\", \"max\"),\n",
    "    destroy_degree_std=(\"destroy_degree\", \"std\"),\n",
    "    destroy_degree_sum=(\"destroy_degree\", \"sum\"),\n",
    "    \n",
    "    # Самописные функции для категорий\n",
    "    work_type_nuniq=(\"work_type\", f_nuniq),\n",
    "    work_type_mode=(\"work_type\", first_mode),\n",
    "    work_type_second_mode=(\"work_type\", second_mode),\n",
    "    \n",
    "    # Самописные функции для численных\n",
    "    destroy_degree_crit_q=(\"destroy_degree\", more_than_n_func),\n",
    "    worker_quant_exp=(\"worker_experience\", quant_func),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864548a2-035d-4517-b36d-968d36fa7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Связка: `pivot()`/`pivot_table()` + `aggfunc()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957145bc-aaba-4e32-8c67-f5e7b55844be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_info_pivot = fix_info.pivot_table(\n",
    "    index=\"car_id\",  # Строка, для которой хотим сгенерировать признаки\n",
    "    columns=[\"work_type\"],  # колонка, которую вытяним в столбец\n",
    "    values=[\"destroy_degree\"],  # столбец, по которой будем считать статистики\n",
    "    aggfunc=[\"mean\", 'count'],  # признаки для генерации (mean/count/sum)\n",
    ").fillna(0)\n",
    "\n",
    "fix_info_pivot.columns = [f\"{i[2]}_{i[0]}\" for i in fix_info_pivot.columns]\n",
    "fix_info_pivot.reset_index(inplace=True)\n",
    "\n",
    "fix_info_pivot.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373a703-cf0f-45bb-aec9-6c3e606a8551",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Рандомы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703c28f-8b9c-43d0-8cc0-0047c4267a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.r_[1:9] # от 1 до 9\n",
    "np.arange(0,np.pi,0.1) # от нуля до пи с шагом 0.1\n",
    "np.cos(np.arange(0,np.pi,0.1))\n",
    "np.linspace(1,5,10) # равномерное разделение\n",
    "np.logspace(2,5,4) # 10 в степени нач., 10 в степени конечной, количество\n",
    "np.geomspace(1,20,3) # начальное, конечное, количество. Геометрическая прогрессия\n",
    "\n",
    "np.random.choice(1000,size=1000, replace =False)\n",
    "np.random.choice(<из_списка>,size=(3,2))\n",
    "np.random.randint(<максимальное>,size = (3,2))\n",
    "np.random.random(10) # кол-во =10, значения от 0 до 1\n",
    "a,b,c = np.random.normal(0,1,size=(3,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5085d5b-5f2d-4f1a-9fbb-930170048d82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1a574-d08b-4d41-a4be-d558bc6417a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train + Test + Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a3f864-8296-48f8-b69a-9abbc1815505",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y) #stratify принимает только одномерный массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad698e5e-804b-44c9-87b4-611f81c650fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение на тренировочные и временные (тест + валидация) данные\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "# Разделим временный на тестовые и валидационные данные\n",
    "test_df, val_df = train_test_split(temp_df, test_size=0.3, random_state=42)  \n",
    "\n",
    "# Вывод размеров полученных наборов данных\n",
    "print(f\"Train set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")\n",
    "print(f\"Validation set: {val_df.shape}\")\n",
    "\n",
    "y_train, y_valid, y_test = train_df['target'], val_df['target'], test_df['target']\n",
    "X_train, X_valid, X_test = train_df[all_features], val_df[all_features], test_df[all_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970313c6-e159-4e22-802e-9f6a4514bf92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train (undersampling) + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb44065-497b-454c-8078-9d25f3adfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на тренировочный и тестовый наборы данных\n",
    "train, test = train_test_split(df_lc, test_size=0.2, random_state=42)\n",
    "\n",
    "# Отбор данных класса 1\n",
    "class_1 = train[train['target'] == 1]\n",
    "# Отбор данных класса 0\n",
    "class_0 = train[train['target'] == 0].sample(n=len(class_1)*2, random_state=42)\n",
    "# Объединение выборок\n",
    "balanced_train = pd.concat([class_1, class_0])\n",
    "\n",
    "X_train_b = balanced_train[all_features]\n",
    "y_train_b = balanced_train['target']\n",
    "\n",
    "X_test_b = test[all_features]\n",
    "y_test_b = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7948999-6c58-410a-8cf0-dcdb70d6097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = list(df_lc.select_dtypes(include=['object']).columns)\n",
    "numeric_features = list(set(df_lc.columns) - (set(categorical_features) | set(['target'])))\n",
    "all_features = categorical_features + numeric_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artem.kolontay_rec_sys_mirr_a:latest",
   "language": "python",
   "name": "second"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
